{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODTcNc2XnuW7",
        "outputId": "6c722325-755a-4599-f270-52fd2c97a119"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The quick brown fox jumps over the horizon.\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "def build_markov_chain(filename: str, chain_length: int) -> dict:\n",
        "    \"\"\"\n",
        "    Build a Markov chain model from the given file.\n",
        "    \"\"\"\n",
        "    # Initialize the Markov chain dictionary\n",
        "    markov_chain = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    # Read the file and build the Markov chain\n",
        "    with open(filename, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "        words = text.split()\n",
        "\n",
        "        # Populate the Markov chain\n",
        "        for i in range(len(words) - chain_length):\n",
        "            # Create the state tuple\n",
        "            state = tuple(words[i:i+chain_length])\n",
        "            next_word = words[i + chain_length]\n",
        "            markov_chain[state][next_word] += 1\n",
        "\n",
        "    # Convert counts to probabilities\n",
        "    for state, next_words in markov_chain.items():\n",
        "        total = sum(next_words.values())\n",
        "        markov_chain[state] = {word: count / total for word, count in next_words.items()}\n",
        "\n",
        "    return markov_chain\n",
        "\n",
        "def generate(filename: str, start_words: list[str], chain_length: int, num_generated: int) -> str:\n",
        "    \"\"\"\n",
        "    Generate a sentence of num_generated words using a Markov chain.\n",
        "    \"\"\"\n",
        "    markov_chain = build_markov_chain(filename, chain_length)\n",
        "\n",
        "    # Ensure start_words length matches the chain length\n",
        "    if len(start_words) != chain_length:\n",
        "        raise ValueError(\"The length of start_words must match the chain_length.\")\n",
        "\n",
        "    current_state = tuple(start_words)\n",
        "    generated_words = list(current_state)\n",
        "\n",
        "    for _ in range(num_generated - chain_length):\n",
        "        next_word_choices = markov_chain.get(current_state, None)\n",
        "        if not next_word_choices:\n",
        "            break  # No further words can be generated from the current state\n",
        "        next_word = random.choices(list(next_word_choices.keys()), list(next_word_choices.values()))[0]\n",
        "        generated_words.append(next_word)\n",
        "\n",
        "        # Update the current state\n",
        "        current_state = tuple(generated_words[-chain_length:])\n",
        "\n",
        "    return ' '.join(generated_words)\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    filename = \"story.txt\"  # Make sure to replace this with your actual file path\n",
        "    start_words = [\"The\", \"quick\"]  # This should match your chain length\n",
        "    chain_length = 2  # Adjust based on your preference\n",
        "    num_generated = 20  # Total number of words you want to generate\n",
        "\n",
        "    generated_sentence = generate(filename, start_words, chain_length, num_generated)\n",
        "    print(generated_sentence)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_markov_chain_generator():\n",
        "    # Define your test cases as tuples: (filename, start_words, chain_length, num_generated)\n",
        "    test_cases = [\n",
        "        (\"test_text_1.txt\", [\"The\", \"cat\"], 2, 10),\n",
        "        (\"test_text_2.txt\", [\"I\", \"love\"], 2, 15),\n",
        "        (\"test_text_3.txt\", [\"Machine\", \"learning\"], 2, 20),\n",
        "    ]\n",
        "\n",
        "    for i, (filename, start_words, chain_length, num_generated) in enumerate(test_cases, start=1):\n",
        "        try:\n",
        "            print(f\"Test Case {i}:\")\n",
        "            generated_sentence = generate(filename, start_words, chain_length, num_generated)\n",
        "            print(f\"Start words: {start_words}\")\n",
        "            print(f\"Generated Sentence: {generated_sentence}\\n\")\n",
        "        except ValueError as e:\n",
        "            print(f\"Test Case {i} failed with error: {e}\\n\")\n",
        "\n",
        "def test_error_conditions():\n",
        "    # Testing with invalid chain length and start words length\n",
        "    try:\n",
        "        print(\"Testing Invalid Chain Length:\")\n",
        "        generate(\"test_text_1.txt\", [\"The\", \"cat\", \"sat\"], 2, 10)\n",
        "    except ValueError as e:\n",
        "        print(f\"Error: {e}\\n\")\n",
        "\n",
        "    try:\n",
        "        print(\"Testing Invalid Start Words Length:\")\n",
        "        generate(\"test_text_1.txt\", [\"The\"], 2, 10)\n",
        "    except ValueError as e:\n",
        "        print(f\"Error: {e}\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_markov_chain_generator()\n",
        "    test_error_conditions()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gM6Vi5qOrQBc",
        "outputId": "265a3ef4-2f43-45c4-97bf-60eae8f09b19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Case 1:\n",
            "Start words: ['The', 'cat']\n",
            "Generated Sentence: The cat ran away.\n",
            "\n",
            "Test Case 2:\n",
            "Start words: ['I', 'love']\n",
            "Generated Sentence: I love eating pizza.\n",
            "\n",
            "Test Case 3:\n",
            "Start words: ['Machine', 'learning']\n",
            "Generated Sentence: Machine learning is used for a variety of applications, such as image recognition and natural language processing.\n",
            "\n",
            "Testing Invalid Chain Length:\n",
            "Error: The length of start_words must match the chain_length.\n",
            "\n",
            "Testing Invalid Start Words Length:\n",
            "Error: The length of start_words must match the chain_length.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}